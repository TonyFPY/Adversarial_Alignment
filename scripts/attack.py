import foolbox as fb
import torchattacks
import torch

class AdversarialAttack_Foolbox:
    def __init__(self, model, attack_name, bounds=(0, 1), model_type='pytorch', preprocessing=None, device=None):
        """
        Initialize the Adversarial attack class.

        Args:
            model (nn.Module): The PyTorch model to attack.
            attack_name (str): The name of the attack to initialize.
            bounds (tuple): The minimum and maximum value of the input data.
            preprocessing (dict): Preprocessing parameters for the model.
            device (str or torch.device): The device to run the attack on.
        """
        self.device = device if device is not None else torch.device('cpu')
        self.model = model.to(self.device).eval()
        self.bounds = bounds
        self.preprocessing = preprocessing if preprocessing is not None else dict(mean=[0, 0, 0], std=[1, 1, 1], axis=-3)

        # Wrap the model using Foolbox's PyTorchModel
        if model_type == 'pytorch':
            self.fb_model = fb.PyTorchModel(
                self.model, bounds=self.bounds, preprocessing=self.preprocessing, device=self.device
            )
        elif model_type == 'tensorflow':
            self.fb_model = fb.TensorFlowModel(
                self.model, bounds=self.bounds, preprocessing=self.preprocessing, device=self.device
            )
        else:
            raise ValueError(f"Unsupported model_type: {model_type}. Please use 'pytorch' or 'tensorflow'.")

        # Store the attack name
        self.attack_name = attack_name

        # Initialize attack parameters inside the class
        self.attack = self.initialize_attack()

    def initialize_attack(self):
        """
        Initialize the adversarial attack based on the given attack name.

        Returns:
            The initialized attack object.
        """
        # Dictionary mapping attack names to Foolbox attacks and their default parameters
        attack_dict = {
            'L2FMNAttack': (
                fb.attacks.L2FMNAttack, {
                    'steps': 1000,
                    'max_stepsize': 1,
                    'min_stepsize': 1e-5,
                    'gamma': 10
                }
            ),
            'L2CarliniWagnerAttack': (
                fb.attacks.L2CarliniWagnerAttack, {
                    'binary_search_steps': 10,
                    'steps': 250,
                    'stepsize': 1e-3,
                    'confidence': 0, 
                    'initial_const': 1e-3,
                    'abort_early': True,
                }
            ),
            'DDNAttack':(
                fb.attacks.DDNAttack, {
                    'init_epsilon': 1.0, 
                    'steps': 1000, 
                    'gamma': 0.05
                }
            ),
            'L2DeepFoolAttack':(
                fb.attacks.L2DeepFoolAttack, {
                    'steps':100,
                    'candidates':2,
                    'overshoot':0.02,
                    'loss':'logits', 
                }
            )
            # Add other attacks as needed
        }

        if self.attack_name not in attack_dict:
            raise ValueError(f"Attack '{self.attack_name}' not recognized. Available attacks: {list(attack_dict.keys())}")

        attack_class, attack_params = attack_dict[self.attack_name]
        
        # Initialize the attack with default parameters
        attack = attack_class(**attack_params)
        return attack

    def run_attack(self, images, labels, epsilons=None):
        """
        Run the attack on the provided images and labels.

        Args:
            images (torch.Tensor): Input images of shape (B, C, H, W).
            labels (torch.Tensor): True labels for the images.
            epsilons (float or list of float, optional): Attack perturbation sizes.

        Returns:
            adv_images (torch.Tensor): Adversarial images generated by the attack.
            clipped_images (torch.Tensor): Clipped adversarial images.
            is_adv (torch.Tensor): Boolean tensor indicating success of the attack for each image.
        """
        images = images.to(self.device)
        labels = labels.to(self.device)

        # Ensure the model is in evaluation mode
        self.model.eval()

        # Run the attack
        # https://foolbox.jonasrauber.de/guide/getting-started.html#attacking-the-model
        adv_images, clipped_images, is_adv = self.attack(self.fb_model, images, labels, epsilons=epsilons)
        return adv_images, clipped_images, is_adv
    
class AdversarialAttack_Torchattacks:
    def __init__(self, model, attack_name, device=None):
        """
        Initializes the attack for the given model and predefined attack configurations.
        
        Parameters:
        - model: The neural network model to attack.
        - attack_name: The name of the attack to use (e.g., 'FAB', 'PGD', 'FGSM').
        """
        self.device = device if device is not None else torch.device('cpu')
        self.model = model.to(self.device).eval()
        self.attack_name = attack_name
        self.attack = self.initialize_attack()

    def initialize_attack(self):
            """
            Initializes the specified attack with predefined parameters.
            
            Returns:
            - An instance of a torchattacks attack.
            """
            if self.attack_name == 'L2FABAttack':
                return torchattacks.FAB(
                    self.model, norm='L2', steps=100, eps=5.0, 
                    n_restarts=5, alpha_max=0.1, eta=1.5, beta=0.5, n_classes=2
                )
            else:
                raise ValueError(f"Attack '{self.attack_name}' not supported or parameters not predefined.")
            
    def run_attack(self, images, labels):
        """
        Generates adversarial images based on the initialized attack.
        
        Parameters:
        - images: The input images to attack.
        - labels: The true labels of the input images.
        
        Returns:
        - Adversarial examples generated from the input images.
        """
        images = images.to(self.device)
        labels = labels.to(self.device)
        
        return self.attack(images, labels)